{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Trajectory Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for simulation\n",
    "from modules.runtime.scenario.scenario_generation.interaction_dataset_scenario_generation import \\\n",
    "    InteractionDatasetScenarioGeneration\n",
    "from modules.runtime.commons.parameters import ParameterServer\n",
    "from modules.runtime.viewer.matplotlib_viewer import MPViewer\n",
    "from modules.runtime.viewer.video_renderer import VideoRenderer\n",
    "import os\n",
    "import os.path\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#debugging\n",
    "import sys\n",
    "\n",
    "#imports for observers\n",
    "from bark_ml.python.bark_ml_library.observers import NearestObserver\n",
    "\n",
    "#imports for -pkl file\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set you directory name from your home\n",
    "repo_directory_name = \"praktikum\"\n",
    "\n",
    "#Set path to interaction dataset\n",
    "path_to_interaction_dataset = os.path.join(os.path.expanduser('~'), repo_directory_name, \"interaction_dataset\")\n",
    "if not os.path.exists(path_to_interaction_dataset):\n",
    "    raise ValueError('Interaction dataset not found at location:', path_to_interaction_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define the secnario:\n",
    "param_server = ParameterServer()\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"MapFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/map/DR_DEU_Merging_MT_v01_shifted.xodr\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/tracks/vehicle_tracks_013.csv\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackIds\"] = [63,64,65,66,67,68]\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"StartTs\"] = 232000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EndTs\"] = 259000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EgoTrackId\"] = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/.cache/bazel/_bazel_pedro/18421c8926ea6aefd77fbccffb5722da/execroot/bark_project/bazel-out/k8-fastbuild/bin/docs/tutorials/run.runfiles/bark_project/modules/runtime/commons/xodr_parser.py:105: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if lane.find(\"userData\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFutureWarning: The behavior of this method will change in future versions. Use specific \\'len(elem)\\' or \\'elem is not None\\' test instead.\\n  if lane.find(\"userData\"):\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scenario\n",
    "scenario_generation = InteractionDatasetScenarioGeneration(num_scenarios=1, random_seed=0, params=param_server)\n",
    "scenario = scenario_generation.create_single_scenario()\n",
    "#following warning will occur:\n",
    "\"\"\"\n",
    "FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
    "  if lane.find(\"userData\"):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "sim_step_time = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for couple of steps\n",
    "world_state = scenario.get_world_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_state.DoPlanning(sim_step_time)\n",
    "world_state.DoExecution(sim_step_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0.20000000298023224\n",
      "['ActionToBehavior', 'Clone', 'GetLastAction', 'Plan', 'SetLastAction', 'SetLastTrajectory', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', 'last_trajectory', 'static_trajectory']\n"
     ]
    }
   ],
   "source": [
    "list_observed_worlds = world_state.Observe(list(range(1,87)))\n",
    "print(list_observed_worlds[1].ego_agent.id)\n",
    "print(list_observed_worlds[1].time)\n",
    "print(dir(list_observed_worlds[1].ego_agent.behavior_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bark.world.World'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AddAgent',\n",
       " 'AddEvaluator',\n",
       " 'AddObject',\n",
       " 'ClearEvaluators',\n",
       " 'Copy',\n",
       " 'DoExecution',\n",
       " 'DoPlanning',\n",
       " 'Evaluate',\n",
       " 'FillWorldFromCarla',\n",
       " 'GetAgent',\n",
       " 'GetNearestAgents',\n",
       " 'GetParams',\n",
       " 'Observe',\n",
       " 'PlanAgents',\n",
       " 'SetMap',\n",
       " 'Step',\n",
       " 'UpdateAgentRTree',\n",
       " 'WorldExecutionAtTime',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'agents',\n",
       " 'agents_valid',\n",
       " 'bounding_box',\n",
       " 'evaluators',\n",
       " 'map',\n",
       " 'objects',\n",
       " 'time']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives as all accessible methods for the world_state\n",
    "print(type(world_state))\n",
    "dir(world_state)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fortiss added a new method for the world class in the recent release:\n",
    "\n",
    "std::vector<ObservedWorld> World::Observe(\n",
    "    const std::vector<AgentId>& agent_ids) {\n",
    "  WorldPtr current_world_state(this->Clone());\n",
    "  std::vector<ObservedWorld> observed_worlds;\n",
    "  for (auto agent_id : agent_ids) {\n",
    "    if (agents_.find(agent_id) == agents_.end()) {\n",
    "      LOG(ERROR) << \"Invalid agent id \" << agent_id << \". Skipping ....\"\n",
    "                 << std::endl;\n",
    "      continue;\n",
    "    }\n",
    "    ObservedWorld observed_world(current_world_state, agent_id);\n",
    "    observed_worlds.push_back(observed_world);\n",
    "  }\n",
    "  return observed_worlds;\n",
    "}\n",
    "    \n",
    "This method let us extract the observed worlds for all active agents (only active agents are stored in the variable agents_). So we dont have to even write our own method! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the observed worlds for the agents at the current timestep\n",
    "list_observed_worlds = world_state.Observe([63,64,65,66,67,68])\n",
    "#type(list_observed_worlds) : list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AddAgent',\n",
       " 'AddEvaluator',\n",
       " 'AddObject',\n",
       " 'ClearEvaluators',\n",
       " 'Copy',\n",
       " 'DoExecution',\n",
       " 'DoPlanning',\n",
       " 'Evaluate',\n",
       " 'FillWorldFromCarla',\n",
       " 'GetAgent',\n",
       " 'GetAgentBehind',\n",
       " 'GetAgentInFront',\n",
       " 'GetNearestAgents',\n",
       " 'GetParams',\n",
       " 'Observe',\n",
       " 'PlanAgents',\n",
       " 'PredictWithOthersIDM',\n",
       " 'SetMap',\n",
       " 'Step',\n",
       " 'UpdateAgentRTree',\n",
       " 'WorldExecutionAtTime',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'agents',\n",
       " 'agents_valid',\n",
       " 'bounding_box',\n",
       " 'ego_agent',\n",
       " 'ego_position',\n",
       " 'ego_state',\n",
       " 'evaluators',\n",
       " 'lane_corridor',\n",
       " 'map',\n",
       " 'objects',\n",
       " 'other_agents',\n",
       " 'road_corridor',\n",
       " 'time']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all methods for an observed world\n",
    "observed_world=list_observed_worlds[0]\n",
    "dir(observed_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unfortunately the method GetEgoAgentID is not accessible for some reasons\n",
    "#to get the agent id we do a small workaround and go over the ego agent and then take his id\n",
    "observed_world.ego_agent.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the .pkl file contain?\n",
    "\n",
    "dict with the keys:\n",
    " - \"obs\" \n",
    " - \"next_obs\" \n",
    " - \"action\" \n",
    " - \"rew\" \n",
    " - \"done\"\n",
    " \n",
    "every key holds a numpy.ndarray of Shape (rows ,  cols), where the number of\n",
    "- rows: are the same for all keys\n",
    "- cols: obs = next_obs = flex , action = flex , rew = done = 1\n",
    "\n",
    "done is 1 if epoche is finished and 0 otherwise"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## First Idea of generating the trajectories of all cars / experts\n",
    "\n",
    "(1) create the complete scenario for a track filename i.e. vehicle_tracks_013.csv\n",
    "TrackIds (=cars) = [0, ,,, , n]\n",
    "StartTs = 0 (microsec)\n",
    "EndTs = z (microsec)\n",
    "EgoTrackId = any TrackId from TrackIds\n",
    "\n",
    "(2) Init Simulation-Specification\n",
    "sim_timestep = minimum is timestep in the dataset or higher (sec)\n",
    "sim_steps = (StartTs-EndTs)/sim_timestep\n",
    "\n",
    "(3) Init the dict\n",
    "-> nested dict with \n",
    "keys as TrackId\n",
    "value as dict with\n",
    "    \"obs\":np.darray(dynamic,obs) -> output of observer\n",
    "    \"next_obs\":np.darray(dynamic,obs) -> output of observer\n",
    "    \"action\":np.darray(dynamic,2) -> steering angle and velocity\n",
    "    \"done\":np.darray(dynamic,1) -> either 0/1\n",
    "    \"time\":np.darray(dynamic,1) -> time in microseconds\n",
    "    \"merge\": true/false -> identification based on road corridor?\n",
    "   \n",
    "(4) Simulation:\n",
    "-1- Initialize World\n",
    "-2- for _ in sim_steps:\n",
    "        World.DoPlanning\n",
    "        World.DoExecution\n",
    "        observed_world_list = World.Observe\n",
    "        \n",
    "-3-     for observed_world in observed_world_list:\n",
    "            get AgentsId of observed_world\n",
    "\n",
    "            if dict[AgentsId] is empty\n",
    "                Init field \"obs\" \"merge\" \"time\" with observed world\n",
    "\n",
    "            else \n",
    "                dict[AgentsId][obs].append(observer(observed_world))\n",
    "                dict[AgentsId][next_obs].append(observer(observed_world))\n",
    "                Actions = Calculate Actions based on difference of current last line in obs and next obs\n",
    "                dict[AgentsId][action].append(Actions)\n",
    "                timestamp = get current worldtime\n",
    "                dict[AgentsId][time].append(timestamp)\n",
    "                dict[AgentsId][done].append(0)\n",
    "-4- Add last row in \"next_obs\" , \"action\" with zeros and \"done\" with 1\n",
    "\n",
    "(5) Store dict to .pkl file\n",
    "\n",
    "## Things we need to do:\n",
    "-> write a function for -3-\n",
    "-> write a function for Action Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Scenario contain (Track_013)\n",
    "\n",
    "Timestamp in ms: starting at 100ms  \n",
    "Every 100ms is next observation -> 100ms frequence  \n",
    "StartTs:100ms  \n",
    "EndTs: 327300ms = 327,3s  \n",
    "cars: 1, ... , 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the complete scenario for a track filename i.e. vehicle_tracks_013.csv\n",
    "\n",
    "#file-specific information\n",
    "\n",
    "#id=18 is not available\n",
    "car_id_list=list(range(1,18))+list(range(19,87))\n",
    "StartTs=100\n",
    "EndTs=327300\n",
    "\n",
    "#Scenario - Set up\n",
    "param_server = ParameterServer()\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"MapFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/map/DR_DEU_Merging_MT_v01_shifted.xodr\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/tracks/vehicle_tracks_013.csv\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackIds\"] = car_id_list\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"StartTs\"] = StartTs\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EndTs\"] = EndTs\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EgoTrackId\"] = 66\n",
    "\n",
    "#Initialize observer\n",
    "observer = NearestObserver(param_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generation = InteractionDatasetScenarioGeneration(num_scenarios=1, random_seed=0, params=param_server)\n",
    "scenario = scenario_generation.create_single_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation-specific configurations\n",
    "speed_factor = 1\n",
    "sim_step_time = 100*speed_factor/1000\n",
    "sim_steps = int((EndTs-StartTs)/(sim_step_time*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the dict\n",
    "\n",
    "#we cant use np.darray directly as it doesnt support dynamic length of a vector\n",
    "#but it can be easily transformend afterwards with array = np.array(list)\n",
    "#list has to be a sequence of lists -> so one list per timestamp appended to the whole list to create two-dim vector\n",
    "\n",
    "expert_traj = {}\n",
    "for agent_id in car_id_list:\n",
    "    expert_traj[agent_id] = {'obs' : [],\n",
    "                             'next_obs': [],\n",
    "                             'action': [],\n",
    "                             'done': [],\n",
    "                             'time': [],\n",
    "                             'merge': []\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calc_action(obs,next_obs,delta_t):\n",
    "    \"\"\"\n",
    "    @Pedro:\n",
    "    here comes your function to get the obs state by observer\n",
    "\n",
    "    Input: \n",
    "        obs : list of observations as a sequence of lists [[x,y,theta,v],[x,y,theta,v]]\n",
    "        next_obs : list of observations as a sequence of lists [[x,y,theta,v],[x,y,theta,v]]\n",
    "        delta_t : the time between two consecutive frames\n",
    "    Output: list with actions [steering_rate,accelaration_rate]\n",
    "    \"\"\"\n",
    "    if delta_t == 0:\n",
    "        print(\"Zero division\")\n",
    "        return [0,0]\n",
    "    \n",
    "    action = []\n",
    "    \n",
    "    # calculate steering rate\n",
    "    action.append((next_obs[2] - obs[2]) / delta_t)\n",
    "    \n",
    "    #just for debugging\n",
    "    action.append((next_obs[3] - obs[3]) / delta_t)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_timestamp_trajectory (exp_traj,obs_world_list,world,observer):\n",
    "    \"\"\"Append the current timestamp trajectory of active agents to expert trajectory\n",
    "    \"\"\"\n",
    "    agents_valid = list(world.agents_valid.keys())\n",
    "    \n",
    "    for obs_world in obs_world_list:\n",
    "    \n",
    "        agent_id = obs_world.ego_agent.id\n",
    "        \n",
    "        if agent_id in agents_valid:\n",
    "            if not exp_traj[agent_id]['obs']:\n",
    "                current_obs = observer.Observe(obs_world)\n",
    "                current_time = [world.time]\n",
    "                \n",
    "                #Calculations for the current step\n",
    "                exp_traj[agent_id]['obs'].append(current_obs)\n",
    "                exp_traj[agent_id]['time'].append(current_time)\n",
    "                \n",
    "                #Other values for the current step are calculated during the next time step\n",
    "\n",
    "                #TBD: check Road-Corridor for first time - for some reasons there is not always a lane available\n",
    "                try:\n",
    "                    exp_traj[agent_id]['merge'].append(obs_world.lane_corridor.center_line.bounding_box[0].x()>900)\n",
    "                except:\n",
    "                    pass\n",
    "                                       \n",
    "\n",
    "            else:\n",
    "                current_obs = observer.Observe(obs_world)\n",
    "                current_time = [world.time]\n",
    "                \n",
    "                previous_obs = exp_traj[agent_id]['obs'][-1]\n",
    "                previous_time = exp_traj[agent_id]['time'][-1]\n",
    "                \n",
    "                #Calculations for previous step\n",
    "                exp_traj[agent_id]['done'].append([0])\n",
    "                exp_traj[agent_id]['next_obs'].append(current_obs)\n",
    "                exp_traj[agent_id]['action'].append(Calc_action(previous_obs, current_obs,\\\n",
    "                                                                current_time[0] - previous_time[0]))\n",
    "                \n",
    "                #Calculations for current step\n",
    "                exp_traj[agent_id]['obs'].append(current_obs)\n",
    "                exp_traj[agent_id]['time'].append(current_time)\n",
    "                \n",
    "                #Check the road corridor if not already defined\n",
    "                if not exp_traj[agent_id]['merge']:\n",
    "                    try:\n",
    "                        exp_traj[agent_id]['merge'].append(obs_world.lane_corridor.center_line.bounding_box[0].x()>900)\n",
    "                    except:\n",
    "                        pass\n",
    "         \n",
    "    return exp_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 1\n",
      "Checkpoint 2\n"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "\n",
    "world_state = scenario.get_world_state()\n",
    "print(\"Checkpoint 1\")\n",
    "for _ in range(0, sim_steps):\n",
    "    world_state.DoPlanning(sim_step_time)\n",
    "    print(\"Checkpoint 2\")\n",
    "    world_state.DoExecution(sim_step_time)\n",
    "    print(\"Checkpoint 3\")\n",
    "    observed_world_list = world_state.Observe(car_id_list)\n",
    "    print(\"Checkpoint 4\")\n",
    "    expert_traj=Append_timestamp_trajectory(expert_traj,observed_world_list,world_state,observer)\n",
    "    print(\"Checkpoint 5\")\n",
    "print(\"Checkpoint 6\")\n",
    "for agent_id in expert_traj:\n",
    "    expert_traj[agent_id]['done'].append([1])\n",
    "    \n",
    "    #add zeros depending on the obs-state size\n",
    "    size = len(expert_traj[agent_id]['next_obs'][-1])\n",
    "    expert_traj[agent_id]['next_obs'].append([0] * size)\n",
    "    \n",
    "    #add zeros depending on the action-state size\n",
    "    expert_traj[agent_id]['action'].append([0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store to dict\n",
    "directory = os.path.join(os.path.expanduser('~'), repo_directory_name, \"bark/docs/tutorial\")\n",
    "filename = 'expert_traj.pickle'\n",
    "\n",
    "with open(os.path.join(directory, filename), 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#Well, now it should hopefully be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do you think pedro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for _ in range(0, sim_time_steps):\n",
    "    world_state.DoPlanning(sim_step_time)\n",
    "    fig = plt.figure(figsize=[10, 10])\n",
    "    viewer = MPViewer(params=param_server, use_world_bounds=True, axis=fig.gca())\n",
    "    viewer.drawWorld(world_state, scenario._eval_agent_ids)\n",
    "    world_state.DoExecution(sim_step_time)\n",
    "    clear_output(wait=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
