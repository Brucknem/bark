{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Trajectory Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for simulation\n",
    "from modules.runtime.scenario.scenario_generation.interaction_dataset_scenario_generation import \\\n",
    "    InteractionDatasetScenarioGeneration\n",
    "from modules.runtime.commons.parameters import ParameterServer\n",
    "from modules.runtime.viewer.matplotlib_viewer import MPViewer\n",
    "from modules.runtime.viewer.video_renderer import VideoRenderer\n",
    "import os\n",
    "import os.path\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#debugging\n",
    "import sys\n",
    "\n",
    "#imports for observers\n",
    "from bark_ml.python.bark_ml_library.observers import NearestObserver\n",
    "\n",
    "#imports for -pkl file\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to interaction dataset\n",
    "#my current path is /home/marvin/Repositories/interaction_dataset\n",
    "path_to_interaction_dataset = os.path.join(os.path.expanduser('~'), \"praktikum/interaction_dataset\")\n",
    "if not os.path.exists(path_to_interaction_dataset):\n",
    "    raise ValueError('Interaction dataset not found at location:', path_to_interaction_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define the secnario:\n",
    "param_server = ParameterServer()\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"MapFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/map/DR_DEU_Merging_MT_v01_shifted.xodr\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/tracks/vehicle_tracks_013.csv\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackIds\"] = [63,64,65,66,67,68]\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"StartTs\"] = 232000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EndTs\"] = 259000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EgoTrackId\"] = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFutureWarning: The behavior of this method will change in future versions. Use specific \\'len(elem)\\' or \\'elem is not None\\' test instead.\\n  if lane.find(\"userData\"):\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scenario\n",
    "scenario_generation = InteractionDatasetScenarioGeneration(num_scenarios=1, random_seed=0, params=param_server)\n",
    "scenario = scenario_generation.create_single_scenario()\n",
    "#following warning will occur:\n",
    "\"\"\"\n",
    "FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
    "  if lane.find(\"userData\"):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "sim_step_time = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for couple of steps\n",
    "world_state = scenario.get_world_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_state.DoPlanning(sim_step_time)\n",
    "world_state.DoExecution(sim_step_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0.20000000298023224\n",
      "['ActionToBehavior', 'Clone', 'GetLastAction', 'Plan', 'SetLastAction', 'SetLastTrajectory', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', 'last_trajectory', 'static_trajectory']\n"
     ]
    }
   ],
   "source": [
    "list_observed_worlds = world_state.Observe(list(range(1,87)))\n",
    "print(list_observed_worlds[1].ego_agent.id)\n",
    "print(list_observed_worlds[1].time)\n",
    "print(dir(list_observed_worlds[1].ego_agent.behavior_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bark.world.World'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AddAgent',\n",
       " 'AddEvaluator',\n",
       " 'AddObject',\n",
       " 'ClearEvaluators',\n",
       " 'Copy',\n",
       " 'DoExecution',\n",
       " 'DoPlanning',\n",
       " 'Evaluate',\n",
       " 'FillWorldFromCarla',\n",
       " 'GetAgent',\n",
       " 'GetNearestAgents',\n",
       " 'GetParams',\n",
       " 'Observe',\n",
       " 'PlanAgents',\n",
       " 'SetMap',\n",
       " 'Step',\n",
       " 'UpdateAgentRTree',\n",
       " 'WorldExecutionAtTime',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'agents',\n",
       " 'agents_valid',\n",
       " 'bounding_box',\n",
       " 'evaluators',\n",
       " 'map',\n",
       " 'objects',\n",
       " 'time']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives as all accessible methods for the world_state\n",
    "print(type(world_state))\n",
    "dir(world_state)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fortiss added a new method for the world class in the recent release:\n",
    "\n",
    "std::vector<ObservedWorld> World::Observe(\n",
    "    const std::vector<AgentId>& agent_ids) {\n",
    "  WorldPtr current_world_state(this->Clone());\n",
    "  std::vector<ObservedWorld> observed_worlds;\n",
    "  for (auto agent_id : agent_ids) {\n",
    "    if (agents_.find(agent_id) == agents_.end()) {\n",
    "      LOG(ERROR) << \"Invalid agent id \" << agent_id << \". Skipping ....\"\n",
    "                 << std::endl;\n",
    "      continue;\n",
    "    }\n",
    "    ObservedWorld observed_world(current_world_state, agent_id);\n",
    "    observed_worlds.push_back(observed_world);\n",
    "  }\n",
    "  return observed_worlds;\n",
    "}\n",
    "    \n",
    "This method let us extract the observed worlds for all active agents (only active agents are stored in the variable agents_). So we dont have to even write our own method! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the observed worlds for the agents at the current timestep\n",
    "list_observed_worlds = world_state.Observe([63,64,65,66,67,68])\n",
    "#type(list_observed_worlds) : list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AddAgent',\n",
       " 'AddEvaluator',\n",
       " 'AddObject',\n",
       " 'ClearEvaluators',\n",
       " 'Copy',\n",
       " 'DoExecution',\n",
       " 'DoPlanning',\n",
       " 'Evaluate',\n",
       " 'FillWorldFromCarla',\n",
       " 'GetAgent',\n",
       " 'GetAgentBehind',\n",
       " 'GetAgentInFront',\n",
       " 'GetNearestAgents',\n",
       " 'GetParams',\n",
       " 'Observe',\n",
       " 'PlanAgents',\n",
       " 'PredictWithOthersIDM',\n",
       " 'SetMap',\n",
       " 'Step',\n",
       " 'UpdateAgentRTree',\n",
       " 'WorldExecutionAtTime',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'agents',\n",
       " 'agents_valid',\n",
       " 'bounding_box',\n",
       " 'ego_agent',\n",
       " 'ego_position',\n",
       " 'ego_state',\n",
       " 'evaluators',\n",
       " 'lane_corridor',\n",
       " 'map',\n",
       " 'objects',\n",
       " 'other_agents',\n",
       " 'road_corridor',\n",
       " 'time']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all methods for an observed world\n",
    "observed_world=list_observed_worlds[0]\n",
    "dir(observed_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unfortunately the method GetEgoAgentID is not accessible for some reasons\n",
    "#to get the agent id we do a small workaround and go over the ego agent and then take his id\n",
    "observed_world.ego_agent.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the .pkl file contain?\n",
    "\n",
    "dict with the keys:\n",
    " - \"obs\" \n",
    " - \"next_obs\" \n",
    " - \"action\" \n",
    " - \"rew\" \n",
    " - \"done\"\n",
    " \n",
    "every key holds a numpy.ndarray of Shape (rows ,  cols), where the number of\n",
    "- rows: are the same for all keys\n",
    "- cols: obs = next_obs = flex , action = flex , rew = done = 1\n",
    "\n",
    "done is 1 if epoche is finished and 0 otherwise"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## First Idea of generating the trajectories of all cars / experts\n",
    "\n",
    "(1) create the complete scenario for a track filename i.e. vehicle_tracks_013.csv\n",
    "TrackIds (=cars) = [0, ,,, , n]\n",
    "StartTs = 0 (microsec)\n",
    "EndTs = z (microsec)\n",
    "EgoTrackId = any TrackId from TrackIds\n",
    "\n",
    "(2) Init Simulation-Specification\n",
    "sim_timestep = minimum is timestep in the dataset or higher (sec)\n",
    "sim_steps = (StartTs-EndTs)/sim_timestep\n",
    "\n",
    "(3) Init the dict\n",
    "-> nested dict with \n",
    "keys as TrackId\n",
    "value as dict with\n",
    "    \"obs\":np.darray(dynamic,obs) -> output of observer\n",
    "    \"next_obs\":np.darray(dynamic,obs) -> output of observer\n",
    "    \"action\":np.darray(dynamic,2) -> steering angle and velocity\n",
    "    \"done\":np.darray(dynamic,1) -> either 0/1\n",
    "    \"time\":np.darray(dynamic,1) -> time in microseconds\n",
    "    \"merge\": true/false -> identification based on road corridor?\n",
    "   \n",
    "(4) Simulation:\n",
    "-1- Initialize World\n",
    "-2- for _ in sim_steps:\n",
    "        World.DoPlanning\n",
    "        World.DoExecution\n",
    "        observed_world_list = World.Observe\n",
    "        \n",
    "-3-     for observed_world in observed_world_list:\n",
    "            get AgentsId of observed_world\n",
    "\n",
    "            if dict[AgentsId] is empty\n",
    "                Init field \"obs\" \"merge\" \"time\" with observed world\n",
    "\n",
    "            else \n",
    "                dict[AgentsId][obs].append(observer(observed_world))\n",
    "                dict[AgentsId][next_obs].append(observer(observed_world))\n",
    "                Actions = Calculate Actions based on difference of current last line in obs and next obs\n",
    "                dict[AgentsId][action].append(Actions)\n",
    "                timestamp = get current worldtime\n",
    "                dict[AgentsId][time].append(timestamp)\n",
    "                dict[AgentsId][done].append(0)\n",
    "-4- Add last row in \"next_obs\" , \"action\" with zeros and \"done\" with 1\n",
    "\n",
    "(5) Store dict to .pkl file\n",
    "\n",
    "## Things we need to do:\n",
    "-> write a function for -3-\n",
    "-> write a function for Action Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Scenario contain (Track_013)\n",
    "\n",
    "Timestamp in ms: starting at 100ms  \n",
    "Every 100ms is next observation -> 100ms frequence  \n",
    "StartTs:100ms  \n",
    "EndTs: 327300ms = 327,3s  \n",
    "cars: 1, ... , 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the complete scenario for a track filename i.e. vehicle_tracks_013.csv\n",
    "\n",
    "#file-specific information\n",
    "\n",
    "#id=18 is not available\n",
    "car_id_list=list(range(1,18))+list(range(19,87))\n",
    "StartTs=100\n",
    "EndTs=327300\n",
    "\n",
    "#Scenario - Set up\n",
    "param_server = ParameterServer()\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"MapFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/map/DR_DEU_Merging_MT_v01_shifted.xodr\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/tracks/vehicle_tracks_013.csv\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackIds\"] = car_id_list\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"StartTs\"] = StartTs\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EndTs\"] = EndTs\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EgoTrackId\"] = 66\n",
    "\n",
    "#Initialize observer\n",
    "observer = NearestObserver(param_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_generation = InteractionDatasetScenarioGeneration(num_scenarios=1, random_seed=0, params=param_server)\n",
    "scenario = scenario_generation.create_single_scenario()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation-specific configurations\n",
    "speed_factor = 1\n",
    "sim_step_time = 100*speed_factor/1000\n",
    "sim_steps = int((EndTs-StartTs)/(sim_step_time*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the dict\n",
    "\n",
    "#we cant use np.darray directly as it doesnt support dynamic length of a vector\n",
    "#but it can be easily transformend afterwards with array = np.array(list)\n",
    "#list has to be a sequence of lists -> so one list per timestamp appended to the whole list to create two-dim vector\n",
    "\n",
    "expert_traj = {}\n",
    "for agent_id in car_id_list:\n",
    "    expert_traj[agent_id] = {'obs' : [],\n",
    "                             'next_obs': [],\n",
    "                             'action': [],\n",
    "                             'done': [],\n",
    "                             'time': [],\n",
    "                             'merge': []\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 2: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 3: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 4: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 5: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 6: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 7: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 8: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 9: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 10: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 11: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 12: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 13: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 14: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 15: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 16: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 17: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 19: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 20: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 21: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 22: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 23: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 24: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 25: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 26: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 27: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 28: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 29: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 30: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 31: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 32: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 33: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 34: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 35: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 36: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 37: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 38: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 39: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 40: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 41: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 42: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 43: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 44: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 45: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 46: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 47: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 48: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 49: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 50: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 51: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 52: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 53: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 54: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 55: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 56: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 57: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 58: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 59: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 60: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 61: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 62: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 63: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 64: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 65: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 66: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 67: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 68: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 69: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 70: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 71: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 72: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 73: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 74: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 75: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 76: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 77: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 78: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 79: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 80: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 81: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 82: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 83: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 84: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 85: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}, 86: {'obs': [], 'next_obs': [], 'action': [], 'done': [], 'time': [], 'merge': []}}\n"
     ]
    }
   ],
   "source": [
    "print(expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calc_Action(obs,next_obs,delta_t):\n",
    "    \"\"\"\n",
    "    @Pedro:\n",
    "    here comes your function to get the obs state by observer\n",
    "\n",
    "    Input: \n",
    "        obs : list of observations as a sequence of lists [[x,y,theta,v],[x,y,theta,v]]\n",
    "        next_obs : list of observations as a sequence of lists [[x,y,theta,v],[x,y,theta,v]]\n",
    "        delta_t : the time between two consecutive frames\n",
    "    Output: list with actions [steering_rate,accelaration_rate]\n",
    "    \"\"\"\n",
    "    action = [0,0]\n",
    "    \n",
    "    # calculate steering angle (angular velocity)\n",
    "    action[0] = (next_obs[2] - obs[2]) / delta_t\n",
    "    \n",
    "    #just for debugging\n",
    "    action[1] = (next_obs[3] - obs[3]) / delta_t\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Obs_State(obs_world):\n",
    "    \"\"\"\n",
    "    @Pedro:\n",
    "    here comes your function to get the obs state by observer\n",
    "\n",
    "    Input: obs_world\n",
    "    Output: list with all information [xpos,ypos,vel,theta,.....]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #just for debugging\n",
    "    obs_state = [0]\n",
    "    \n",
    "    return obs_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_timestamp_trajectory (exp_traj,obs_world_list,world):\n",
    "    \"\"\"Append the current timestamp trajectory of active agents to expert trajectory\n",
    "    \"\"\"\n",
    "    agents_valid = list(world.agents_valid.keys())\n",
    "    \n",
    "    for obs_world in obs_world_list:\n",
    "    \n",
    "        agent_id = obs_world.ego_agent.id\n",
    "        \n",
    "        if agent_id in agents_valid:\n",
    "            if not exp_traj[agent_id]['obs']:\n",
    "                exp_traj[agent_id]['obs'].append(Create_Obs_State(obs_world))\n",
    "                #\n",
    "\n",
    "                exp_traj[agent_id]['time'].append([world.time])\n",
    "\n",
    "                #TBD: check Road-Corridor for first time - for some reasons there is not always a lane available\n",
    "                try:\n",
    "                    exp_traj[agent_id]['merge'].append(obs_world.lane_corridor.center_line.bounding_box[0].x()>900)\n",
    "                except:\n",
    "                    pass\n",
    "                                       \n",
    "\n",
    "            else:\n",
    "\n",
    "                #@Pedro\n",
    "                #TBD: add the oberserver + possible return transformation\n",
    "                #TBD: add a function to Calculate the action based on two observation\n",
    "                exp_traj[agent_id]['obs'].append(Create_Obs_State(obs_world))    \n",
    "                exp_traj[agent_id]['next_obs'].append(exp_traj[agent_id]['obs'][-1])\n",
    "                exp_traj[agent_id]['action'].append(Calc_Action(exp_traj[agent_id]['obs'][-1],\\\n",
    "                                                                exp_traj[agent_id]['next_obs'][-1], \\\n",
    "                                                                exp_traj[agent_id]['time'][-1][0] - exp_traj[agent_id]['time'][-2][0]))\n",
    "                #\n",
    "\n",
    "                #Check the road corridor if not already defined\n",
    "                if not exp_traj[agent_id]['merge']:\n",
    "                    try:\n",
    "                        exp_traj[agent_id]['merge'].append(obs_world.lane_corridor.center_line.bounding_box[0].x()>900)\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "                        \n",
    "                exp_traj[agent_id]['done'].append([0])         \n",
    "                exp_traj[agent_id]['time'].append([world.time])\n",
    "         \n",
    "    return exp_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5b64a6fdca6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mworld_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoExecution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_step_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mobserved_world_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworld_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_id_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mexpert_traj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAppend_timestamp_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpert_traj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobserved_world_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworld_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0magent_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpert_traj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-d6332f27417f>\u001b[0m in \u001b[0;36mAppend_timestamp_trajectory\u001b[0;34m(exp_traj, obs_world_list, world)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 exp_traj[agent_id]['action'].append(Calc_Action(exp_traj[agent_id]['obs'][-1],\\\n\u001b[1;32m     34\u001b[0m                                                                 \u001b[0mexp_traj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_obs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                                                                 exp_traj[agent_id]['time'][-1][0] - exp_traj[agent_id]['time'][-2][0]))\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "\n",
    "world_state = scenario.get_world_state()\n",
    "\n",
    "for _ in range(0, sim_steps):\n",
    "    world_state.DoPlanning(sim_step_time)\n",
    "    world_state.DoExecution(sim_step_time)\n",
    "    observed_world_list = world_state.Observe(car_id_list)\n",
    "    expert_traj=Append_timestamp_trajectory(expert_traj,observed_world_list,world_state)\n",
    "\n",
    "for agent_id in expert_traj:\n",
    "    \n",
    "    #@Pedro\n",
    "    #add zeros depending on the obs-state size\n",
    "    expert_traj[agent_id]['next_obs'].append([0])\n",
    "    #add zeros depending on the action-state size\n",
    "    expert_traj[agent_id]['action'].append([0,0])\n",
    "    #or we duplicate the 'obs' and 'action' so no difficult sizing has to be done....\n",
    "    \n",
    "    expert_traj[agent_id]['done'].append([1])        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store to dict\n",
    "#@Pedro can you implement this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do you think pedro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for _ in range(0, sim_time_steps):\n",
    "    world_state.DoPlanning(sim_step_time)\n",
    "    fig = plt.figure(figsize=[10, 10])\n",
    "    viewer = MPViewer(params=param_server, use_world_bounds=True, axis=fig.gca())\n",
    "    viewer.drawWorld(world_state, scenario._eval_agent_ids)\n",
    "    world_state.DoExecution(sim_step_time)\n",
    "    clear_output(wait=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
