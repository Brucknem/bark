{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Trajectory Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for simulation\n",
    "from modules.runtime.scenario.scenario_generation.interaction_dataset_scenario_generation import \\\n",
    "    InteractionDatasetScenarioGeneration\n",
    "from modules.runtime.commons.parameters import ParameterServer\n",
    "from modules.runtime.viewer.matplotlib_viewer import MPViewer\n",
    "from modules.runtime.viewer.video_renderer import VideoRenderer\n",
    "import os\n",
    "import os.path\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#imports for observers\n",
    "\n",
    "#imports for -pkl file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to interaction dataset\n",
    "#my current path is /home/marvin/Repositories/interaction_dataset\n",
    "path_to_interaction_dataset = os.path.join(os.path.expanduser('~'), \"Repositories/interaction_dataset\")\n",
    "if not os.path.exists(path_to_interaction_dataset):\n",
    "    raise ValueError('Interaction dataset not found at location:', path_to_interaction_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define the secnario:\n",
    "param_server = ParameterServer()\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"MapFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/map/DR_DEU_Merging_MT_v01_shifted.xodr\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackFilename\"] = os.path.join(path_to_interaction_dataset, \"DR_DEU_Merging_MT/tracks/vehicle_tracks_013.csv\")\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"TrackIds\"] = [63,64,65,66,67,68]\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"StartTs\"] = 232000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EndTs\"] = 259000\n",
    "param_server[\"Scenario\"][\"Generation\"][\"InteractionDatasetScenarioGeneration\"][\"EgoTrackId\"] = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marvin/.cache/bazel/_bazel_marvin/d2ffea8a3be3f61c262349ab2b5fa373/execroot/bark_project/bazel-out/k8-fastbuild/bin/docs/tutorials/run.runfiles/bark_project/modules/runtime/commons/xodr_parser.py:105: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if lane.find(\"userData\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFutureWarning: The behavior of this method will change in future versions. Use specific \\'len(elem)\\' or \\'elem is not None\\' test instead.\\n  if lane.find(\"userData\"):\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the scenario\n",
    "scenario_generation = InteractionDatasetScenarioGeneration(num_scenarios=1, random_seed=0, params=param_server)\n",
    "scenario = scenario_generation.create_single_scenario()\n",
    "#following warning will occur:\n",
    "\"\"\"\n",
    "FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
    "  if lane.find(\"userData\"):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "sim_step_time = 0.2\n",
    "sim_time_steps = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation for couple of steps\n",
    "world_state = scenario.get_world_state()\n",
    "for _ in range(0, 20):\n",
    "    world_state.DoPlanning(sim_step_time)\n",
    "    world_state.DoExecution(sim_step_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bark.world.World'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AddAgent',\n",
       " 'AddEvaluator',\n",
       " 'AddObject',\n",
       " 'ClearEvaluators',\n",
       " 'Copy',\n",
       " 'DoExecution',\n",
       " 'DoPlanning',\n",
       " 'Evaluate',\n",
       " 'FillWorldFromCarla',\n",
       " 'GetAgent',\n",
       " 'GetNearestAgents',\n",
       " 'GetParams',\n",
       " 'Observe',\n",
       " 'PlanAgents',\n",
       " 'SetMap',\n",
       " 'Step',\n",
       " 'UpdateAgentRTree',\n",
       " 'WorldExecutionAtTime',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'agents',\n",
       " 'agents_valid',\n",
       " 'bounding_box',\n",
       " 'evaluators',\n",
       " 'map',\n",
       " 'objects',\n",
       " 'time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives as all accessible methods for the world_state\n",
    "print(type(world_state))\n",
    "dir(world_state)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fortiss added a new method for the world class in the recent release:\n",
    "\n",
    "std::vector<ObservedWorld> World::Observe(\n",
    "    const std::vector<AgentId>& agent_ids) {\n",
    "  WorldPtr current_world_state(this->Clone());\n",
    "  std::vector<ObservedWorld> observed_worlds;\n",
    "  for (auto agent_id : agent_ids) {\n",
    "    if (agents_.find(agent_id) == agents_.end()) {\n",
    "      LOG(ERROR) << \"Invalid agent id \" << agent_id << \". Skipping ....\"\n",
    "                 << std::endl;\n",
    "      continue;\n",
    "    }\n",
    "    ObservedWorld observed_world(current_world_state, agent_id);\n",
    "    observed_worlds.push_back(observed_world);\n",
    "  }\n",
    "  return observed_worlds;\n",
    "}\n",
    "    \n",
    "This method let us extract the observed worlds for all active agents (only active agents are stored in the variable agents_). So we dont have to even write our own method! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of the observed worlds for the agents at the current timestep\n",
    "list_observed_worlds = world_state.Observe([63,64,65,66,67,68])\n",
    "#type(list_observed_worlds) : list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AddAgent',\n",
       " 'AddEvaluator',\n",
       " 'AddObject',\n",
       " 'ClearEvaluators',\n",
       " 'Copy',\n",
       " 'DoExecution',\n",
       " 'DoPlanning',\n",
       " 'Evaluate',\n",
       " 'FillWorldFromCarla',\n",
       " 'GetAgent',\n",
       " 'GetAgentBehind',\n",
       " 'GetAgentInFront',\n",
       " 'GetNearestAgents',\n",
       " 'GetParams',\n",
       " 'Observe',\n",
       " 'PlanAgents',\n",
       " 'PredictWithOthersIDM',\n",
       " 'SetMap',\n",
       " 'Step',\n",
       " 'UpdateAgentRTree',\n",
       " 'WorldExecutionAtTime',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'agents',\n",
       " 'agents_valid',\n",
       " 'bounding_box',\n",
       " 'ego_agent',\n",
       " 'ego_position',\n",
       " 'ego_state',\n",
       " 'evaluators',\n",
       " 'lane_corridor',\n",
       " 'map',\n",
       " 'objects',\n",
       " 'other_agents',\n",
       " 'road_corridor',\n",
       " 'time']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all methods for an observed world\n",
    "observed_world=list_observed_worlds[0]\n",
    "dir(observed_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unfortunately the method GetEgoAgentID is not accessible for some reasons\n",
    "#to get the agent id we do a small workaround and go over the ego agent and then take his id\n",
    "observed_world.ego_agent.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the .pkl file contain?\n",
    "\n",
    "dict with the keys:\n",
    " - \"obs\" \n",
    " - \"next_obs\" \n",
    " - \"action\" \n",
    " - \"rew\" \n",
    " - \"done\"\n",
    " \n",
    "every key holds a numpy.ndarray of Shape (rows ,  cols), where the number of\n",
    "- rows: are the same for all keys\n",
    "- cols: obs = next_obs = flex , action = flex , rew = done = 1\n",
    "\n",
    "done is 1 if epoche is finished and 0 otherwise"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## First Idea of generating the trajectories of all cars / experts\n",
    "\n",
    "(1) create the complete scenario for a track filename i.e. vehicle_tracks_013.csv\n",
    "TrackIds (=cars) = [0, ,,, , n]\n",
    "StartTs = 0 (microsec)\n",
    "EndTs = z (microsec)\n",
    "EgoTrackId = any TrackId from TrackIds\n",
    "\n",
    "(2) Init Simulation-Specification\n",
    "sim_timestep = minimum is timestep in the dataset or higher (sec)\n",
    "sim_steps = (StartTs-EndTs)/sim_timestep\n",
    "\n",
    "(3) Init the dict\n",
    "-> nested dict with \n",
    "keys as TrackId\n",
    "value as dict with\n",
    "    \"obs\":np.darray(dynamic,obs) -> output of observer\n",
    "    \"next_obs\":np.darray(dynamic,obs) -> output of observer\n",
    "    \"action\":np.darray(dynamic,2) -> steering angle and velocity\n",
    "    \"done\":np.darray(dynamic,1) -> either 0/1\n",
    "    \"time\":np.darray(dynamic,1) -> time in microseconds\n",
    "    \"merge\": true/false -> identification based on road corridor?\n",
    "   \n",
    "(4) Simulation:\n",
    "-1- Initialize World\n",
    "-2- for _ in sim_steps:\n",
    "        World.DoPlanning\n",
    "        World.DoExecution\n",
    "        observed_world_list = World.Observe\n",
    "        \n",
    "-3-     for observed_world in observed_world_list:\n",
    "            get AgentsId of observed_world\n",
    "\n",
    "            if dict[AgentsId] is empty\n",
    "                Init field \"obs\" \"merge\" \"time\" with observed world\n",
    "\n",
    "            else \n",
    "                dict[AgentsId][obs].append(observer(observed_world))\n",
    "                dict[AgentsId][next_obs].append(observer(observed_world))\n",
    "                Actions = Calculate Actions based on difference of current last line in obs and next obs\n",
    "                dict[AgentsId][action].append(Actions)\n",
    "                timestamp = get current worldtime\n",
    "                dict[AgentsId][time].append(timestamp)\n",
    "                dict[AgentsId][done].append(0)\n",
    "-4- Add last row in \"next_obs\" , \"action\" with zeros and \"done\" with 1\n",
    "\n",
    "(5) Store dict to .pkl file\n",
    "\n",
    "## Things we need to do:\n",
    "-> write a function for -3-\n",
    "-> write a function for Action Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for _ in range(0, sim_time_steps):\n",
    "    world_state.DoPlanning(sim_step_time)\n",
    "    fig = plt.figure(figsize=[10, 10])\n",
    "    viewer = MPViewer(params=param_server, use_world_bounds=True, axis=fig.gca())\n",
    "    viewer.drawWorld(world_state, scenario._eval_agent_ids)\n",
    "    world_state.DoExecution(sim_step_time)\n",
    "    clear_output(wait=True)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
